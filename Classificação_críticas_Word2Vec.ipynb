{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3_Q5rojPwkI"
   },
   "source": [
    "# Importação dos módulos e Leitura da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGTNU5quQJE8"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KEqnHdXoHdd"
   },
   "outputs": [],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8WqxMA1jlNt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from string import punctuation\n",
    "import unidecode\n",
    "from gensim.models import KeyedVectors\n",
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9s6yfYDW6usg"
   },
   "outputs": [],
   "source": [
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5Qw03kUBYve"
   },
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gg4dd6F0QYAK"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/Mineração de Texto e Processamento de Linguagem Natural/Material de Apoio/criticas-imdb.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xT7hr-6GRLcA"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/My Drive/Mineração de Texto e Processamento de Linguagem Natural/Material de Apoio/cbow_s300.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLAmO6KWgfxt"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/My Drive/Mineração de Texto e Processamento de Linguagem Natural/Material de Apoio/skip_s300.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHJzaeICP6aH"
   },
   "outputs": [],
   "source": [
    "criticas = pd.read_csv(\"criticas-imdb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2q0wpDXhkd_"
   },
   "source": [
    "# Limpeza dos textos de crítica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9Dto4FPyJXq"
   },
   "source": [
    "### Eliminando acentuação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yg70LfhTlWLu"
   },
   "outputs": [],
   "source": [
    "tokenizadorPontuacaoEspacos = tokenize.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxW9NmpzyJXr"
   },
   "outputs": [],
   "source": [
    "textos_criticas_sem_acentos = [unidecode.unidecode(texto) for texto in list(criticas.texto)]\n",
    "textos_criticas_sem_acentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jq023WwyJXs"
   },
   "outputs": [],
   "source": [
    "textos_processados = list()\n",
    "for texto in textos_criticas_sem_acentos:\n",
    "  tokens_texto = tokenizadorPontuacaoEspacos.tokenize(texto)\n",
    "  tokens_texto_limpo = list()\n",
    "  for token in tokens_texto:\n",
    "    tokens_texto_limpo.append(token)\n",
    "  textos_processados.append(' '.join(tokens_texto_limpo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP1R2vmQktBn"
   },
   "source": [
    "### Eliminando as palavras irrelevantes e a pontuação dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "giKc2Q3ajCiw"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "palavras_irrelevantes = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gc5ynYS1mHnn"
   },
   "outputs": [],
   "source": [
    "# Função para colocar as pontuações em uma lista\n",
    "pontuacoes = list()\n",
    "for pontuacao in punctuation:\n",
    "  pontuacoes.append(pontuacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijun3UV-mU4w"
   },
   "outputs": [],
   "source": [
    "# Pontuações e palavras irrelevantes em uma lista só\n",
    "pontuacoes_e_palavras_irrelevantes = pontuacoes + palavras_irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGge_zJRkFd4"
   },
   "outputs": [],
   "source": [
    "# Função para eliminar as palavras irrelevantes e a pontuação\n",
    "textos_processados_2 = list()\n",
    "for texto in textos_processados:\n",
    "  tokens_texto = tokenizadorPontuacaoEspacos.tokenize(texto)\n",
    "  tokens_texto_limpo = list()\n",
    "  for token in tokens_texto:\n",
    "    if token not in pontuacoes_e_palavras_irrelevantes:\n",
    "      tokens_texto_limpo.append(token)\n",
    "  textos_processados_2.append(' '.join(tokens_texto_limpo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKOu-BnTrYUE"
   },
   "source": [
    "### Deixando todo o texto com letras minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TagUj7sQq_Go"
   },
   "outputs": [],
   "source": [
    "textos_processados_3 = list()\n",
    "for texto in textos_processados_2:\n",
    "  texto = texto.lower()\n",
    "  tokens_texto = tokenizadorPontuacaoEspacos.tokenize(texto)\n",
    "  tokens_texto_limpo = list()\n",
    "  for token in tokens_texto:\n",
    "    # if token not in pontuacoes_e_palavras_irrelevantes_sem_acentos:\n",
    "    tokens_texto_limpo.append(token)\n",
    "  textos_processados_3.append(' '.join(tokens_texto_limpo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FU_c2110soB"
   },
   "source": [
    "### Stemização dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L04rEkom0rYd"
   },
   "outputs": [],
   "source": [
    "stemizador = nltk.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oN1lBgmn067Y"
   },
   "outputs": [],
   "source": [
    "textos_processados_4 = list()\n",
    "for texto in textos_processados_3:\n",
    "  tokens_texto = tokenizadorPontuacaoEspacos.tokenize(texto)\n",
    "  tokens_stemizados = [stemizador.stem(token) for token in tokens_texto]\n",
    "  textos_processados_4.append(' '.join(tokens_stemizados))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38_zeihR9qIF"
   },
   "source": [
    "## Colocando a lista dos textos tratados na base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T68_xT3L9f3G"
   },
   "outputs": [],
   "source": [
    "criticas[\"textos_tratados\"]=textos_processados_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76b79r5rfdaZ"
   },
   "source": [
    "# Divisão da base de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnjF5SY2fdaa"
   },
   "outputs": [],
   "source": [
    "criticas_treino, criticas_teste = train_test_split(criticas, test_size=0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTt_O5C1fyAC"
   },
   "source": [
    "# Funções que auxiliarão a classificação dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jFS4HIjBstc"
   },
   "outputs": [],
   "source": [
    "# Função para tokenizar os textos\n",
    "def tratarTokenizar(texto):\n",
    "  texto=texto.lower()\n",
    "  tokens_validos = []\n",
    "\n",
    "  for token in nltk.word_tokenize(texto):\n",
    "    if token not in string.punctuation:\n",
    "      tokens_validos.append(token)\n",
    "\n",
    "  return tokens_validos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEkTYAaPCGpJ"
   },
   "outputs": [],
   "source": [
    "# Função para somar valores para cada token do texto de crítica de acordo com o modelo\n",
    "def somaVetores(tokens, modelo):\n",
    "  vetorSomado = np.zeros(300)\n",
    "  for token in tokens:\n",
    "    try:\n",
    "      vetorSomado += modelo.get_vector(token)\n",
    "    except:\n",
    "      if token.isnumeric() and len(token) <= 15:\n",
    "        token = \"0\"*len(token)\n",
    "        vetorSomado += modelo.get_vector(token)\n",
    "      elif token.isnumeric() and len(token) > 15:\n",
    "        token = \"0\"*15\n",
    "        vetorSomado += modelo.get_vector(token)\n",
    "      else:\n",
    "        vetorSomado += modelo.get_vector(\"unknown\")\n",
    "        \n",
    "  return vetorSomado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzNh7eb8DX5l"
   },
   "outputs": [],
   "source": [
    "# Função para construir a base de dados que será treinada e testada de acordo com o modelo\n",
    "def vetoresTextos(textos, modelo):\n",
    "  x = len(textos)\n",
    "  y = 300\n",
    "  vetores = np.zeros((x,y))\n",
    "\n",
    "  for itexto in range(x):\n",
    "    tokens = tratarTokenizar(textos.iloc[itexto])\n",
    "    vetores[itexto] = somaVetores(tokens, modelo)\n",
    "\n",
    "  return vetores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhUbJIHohe2m"
   },
   "source": [
    "# Classificando com modelo Word2Vec (CBOW) - Textos tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zwRR9omAhe2o"
   },
   "outputs": [],
   "source": [
    "# Importando o arquivo txt com o modelo cbow\n",
    "modelo_cbow = KeyedVectors.load_word2vec_format(\"cbow_s300.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idtJIW_DgBfj"
   },
   "source": [
    "### Cálculo dos vetores de treino e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm0g9rzQX52u"
   },
   "outputs": [],
   "source": [
    "vetores_treino = vetoresTextos(criticas_treino.textos_tratados, modelo_cbow)\n",
    "vetores_teste = vetoresTextos(criticas_teste.textos_tratados, modelo_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmAD4l9mYEGB"
   },
   "source": [
    "### Geração do Modelo e avaliação da classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXiPemYBYRT8"
   },
   "outputs": [],
   "source": [
    "classificador_cbow = LogisticRegression(max_iter=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K981Q0H0YRT9"
   },
   "outputs": [],
   "source": [
    "classificador_cbow.fit(vetores_treino, criticas_treino.sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfyCefSoYRT9"
   },
   "outputs": [],
   "source": [
    "classificador_cbow.score(vetores_teste, criticas_teste.sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1666121241999,
     "user": {
      "displayName": "Willian Alecsander Farias Costa",
      "userId": "06668607203888333009"
     },
     "user_tz": 180
    },
    "id": "cb-5I6I8YRT-",
    "outputId": "b84ea6f8-cbe5-4745-c7bd-9b4eaafd8bde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.77      0.75      0.76      4991\n",
      "    positivo       0.75      0.77      0.76      4901\n",
      "\n",
      "    accuracy                           0.76      9892\n",
      "   macro avg       0.76      0.76      0.76      9892\n",
      "weighted avg       0.76      0.76      0.76      9892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimentos_previstos = classificador_cbow.predict(vetores_teste)\n",
    "relatorio = classification_report(criticas_teste.sentimento, sentimentos_previstos)\n",
    "print(relatorio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dONpKRYriBB7"
   },
   "source": [
    "# Classificando com modelo Word2Vec (CBOW) - Textos não tratados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hfSKR9igbcL"
   },
   "source": [
    "### Cálculo dos vetores de treino e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMHL6g9WEIkM"
   },
   "outputs": [],
   "source": [
    "# Cálculo dos vetores de treino e de teste\n",
    "vetores_treino2 = vetoresTextos(criticas_treino.texto, modelo_cbow)\n",
    "vetores_teste2 = vetoresTextos(criticas_teste.texto, modelo_cbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csHCzbb8R7W4"
   },
   "source": [
    "### Geração do Modelo e avaliação da classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHy_B45APcY_"
   },
   "outputs": [],
   "source": [
    "classificador_cbow2 = LogisticRegression(max_iter=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3kdFPGnPtUV"
   },
   "outputs": [],
   "source": [
    "classificador_cbow2.fit(vetores_treino2, criticas_treino.sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FOW8NQTQaA2"
   },
   "outputs": [],
   "source": [
    "classificador_cbow2.score(vetores_teste2, criticas_teste.sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1666120281044,
     "user": {
      "displayName": "Willian Alecsander Farias Costa",
      "userId": "06668607203888333009"
     },
     "user_tz": 180
    },
    "id": "gAwCIpEsQ2ro",
    "outputId": "eb410305-42a8-4398-eafb-940ac85e08ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.81      0.81      0.81      4991\n",
      "    positivo       0.80      0.80      0.80      4901\n",
      "\n",
      "    accuracy                           0.80      9892\n",
      "   macro avg       0.80      0.80      0.80      9892\n",
      "weighted avg       0.80      0.80      0.80      9892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimentos_previstos2 = classificador_cbow2.predict(vetores_teste)\n",
    "relatorio2 = classification_report(criticas_teste.sentimento, sentimentos_previstos2)\n",
    "print(relatorio2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8Rn5b2Wa_cP"
   },
   "source": [
    "# Classificando com modelo Word2Vec (SkipGram) - Textos tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEmC2CExa-rh"
   },
   "outputs": [],
   "source": [
    "# Importando o arquivo txt com o modelo SkipGram\n",
    "modelo_skipgram = KeyedVectors.load_word2vec_format(\"skip_s300.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxvTh1Y3iR_3"
   },
   "source": [
    "### Cálculo dos vetores de treino e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jgz5bGEybLsh"
   },
   "outputs": [],
   "source": [
    "vetores_treino_skipgram = vetoresTextos(criticas_treino.textos_tratados, modelo_skipgram)\n",
    "vetores_teste_skipgram = vetoresTextos(criticas_teste.textos_tratados, modelo_skipgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7t7lJKJemGV"
   },
   "source": [
    "### Geração do Modelo e avaliação da classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8aUzF0icuST"
   },
   "outputs": [],
   "source": [
    "classificador_skipgram = LogisticRegression(max_iter=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJIQMrksd1u_"
   },
   "outputs": [],
   "source": [
    "classificador_skipgram.fit(vetores_treino_skipgram, criticas_treino.sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1666120758448,
     "user": {
      "displayName": "Willian Alecsander Farias Costa",
      "userId": "06668607203888333009"
     },
     "user_tz": 180
    },
    "id": "z_49hZz5c11J",
    "outputId": "d12437b2-aa47-4760-b0c8-b7973d9d7753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.77      0.75      0.76      4991\n",
      "    positivo       0.75      0.78      0.77      4901\n",
      "\n",
      "    accuracy                           0.76      9892\n",
      "   macro avg       0.76      0.76      0.76      9892\n",
      "weighted avg       0.76      0.76      0.76      9892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimentos_previstos_skipgram = classificador_skipgram.predict(vetores_teste_skipgram)\n",
    "relatorio_skipgram = classification_report(criticas_teste.sentimento, sentimentos_previstos_skipgram)\n",
    "print(relatorio_skipgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USk7r7LsiObo"
   },
   "source": [
    "# Classificando com modelo Word2Vec (SkipGram) - Textos não tratados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJAUsRCuiipG"
   },
   "source": [
    "### Cálculo dos vetores de treino e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHc544wGiObq"
   },
   "outputs": [],
   "source": [
    "vetores_treino_skipgram2 = vetoresTextos(criticas_treino.texto, modelo_skipgram)\n",
    "vetores_teste_skipgram2 = vetoresTextos(criticas_teste.texto, modelo_skipgram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSOaRSOLiObr"
   },
   "source": [
    "### Geração do Modelo e avaliação da classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XA_4BywEiObr"
   },
   "outputs": [],
   "source": [
    "classificador_skipgram2 = LogisticRegression(max_iter=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jj26N8x0iObs"
   },
   "outputs": [],
   "source": [
    "classificador_skipgram2.fit(vetores_treino_skipgram2, criticas_treino.sentimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1666120983904,
     "user": {
      "displayName": "Willian Alecsander Farias Costa",
      "userId": "06668607203888333009"
     },
     "user_tz": 180
    },
    "id": "PJ_KJjdViObs",
    "outputId": "3997f55e-6639-4433-b0ec-09ee49643978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.81      0.81      0.81      4991\n",
      "    positivo       0.81      0.81      0.81      4901\n",
      "\n",
      "    accuracy                           0.81      9892\n",
      "   macro avg       0.81      0.81      0.81      9892\n",
      "weighted avg       0.81      0.81      0.81      9892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentimentos_previstos_skipgram2 = classificador_skipgram2.predict(vetores_teste_skipgram2)\n",
    "relatorio_skipgram2 = classification_report(criticas_teste.sentimento, sentimentos_previstos_skipgram2)\n",
    "print(relatorio_skipgram2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx6qMhXCibBE"
   },
   "source": [
    "# Avaliação dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7A58YkDigtE"
   },
   "source": [
    "Observando os resultados gerados, pode-se perceber que os classificadores do modelo CBOW e SkipGram obtiveram resultados semelhantes. \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HvQACh9j_6j"
   },
   "source": [
    "Para os textos não-tratados sobre as críticas, apenas a precisão e a revogação para as críticas que foram rotuladas como positivas tiveram ligeira melhora no modelo SkipGram, saindo de 0,8 no modelo CBOW e indo para 0,81.\n",
    "\n",
    "Para os textos tratados, os resultados de performance em relação aos modelos foram praticamente os mesmos, variando entre 0,75 e 0,78. Pode-se perceber também que o tratamento dos textos (eliminação de palavras irrelevantes, pontuação, acentuação e stemização das palavras derivadas) piorou a performance dos dois modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5FugVpyV5R-"
   },
   "source": [
    "Comparando esses resultados com os que foram obtidos com o uso da técnica bag-of-words na Unidade 2 pode-se perceber que ocorreu um resultado inverso. \n",
    "\n",
    "Na técnica bag-of-words, o classificador teve uma performance de 0.65 de acurácia com os textos não-tratados. Essa performance chegou a 0.82 com a eliminação de palavras irrelevantes, pontuações e acentuações além da stemização das palavras derivadas e, por fim, chegou a 0.88 com o uso da técnica TF-IDF e dos bigramas de palavras. \n",
    "\n",
    "Já nesta técnica que usou os modelos CBOW e SkipGram, o tratamento dos textos fez com que as performances dos classificadores piorassem."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNxjQAPPPC+1LA5jSavO0Io",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
